#!/usr/bin/env python3
"""
DeepSpace Matrix Daily - æµ‹è¯•è„šæœ¬
æµ‹è¯•åˆ†ç±»èšåˆåŠŸèƒ½
"""
import sys
from pathlib import Path
import json
from datetime import datetime, timedelta
import pytz

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent / 'src'))

from content_classifier import ContentClassifier
from content_aggregator import ContentAggregator
from summary_generator import SummaryGenerator

def test_classification():
    """æµ‹è¯•å†…å®¹åˆ†ç±»åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•å†…å®¹åˆ†ç±»åŠŸèƒ½...")
    
    classifier = ContentClassifier("config/categories.json")
    
    # æµ‹è¯•æ–‡ç« 
    test_articles = [
        {
            "title": "OpenAIå‘å¸ƒæ–°ä¸€ä»£è¯­è¨€æ¨¡å‹",
            "summary": "OpenAIä»Šæ—¥å‘å¸ƒäº†å…¨æ–°çš„è¯­è¨€æ¨¡å‹ï¼Œæ€§èƒ½ç›¸æ¯”å‰ä»£æå‡æ˜¾è‘—...",
            "source": "TechCrunch",
            "author": "John Smith",
            "published_at": datetime.now(pytz.UTC),
            "url": "https://example.com/article1"
        },
        {
            "title": "å¦‚ä½•é«˜æ•ˆå­¦ä¹ ç®—æ³•",
            "summary": "æœ¬æ–‡ä»‹ç»äº†å‡ ç§é«˜æ•ˆå­¦ä¹ ç®—æ³•çš„æ–¹æ³•å’Œå®è·µæŠ€å·§...",
            "source": "Hacker News",
            "author": "Jane Doe",
            "published_at": datetime.now(pytz.UTC),
            "url": "https://example.com/article2"
        },
        {
            "title": "è‚¡å¸‚ä»Šæ—¥åˆ†æ",
            "summary": "ä»Šæ—¥è‚¡å¸‚å‡ºç°å¤§å¹…æ³¢åŠ¨ï¼Œç§‘æŠ€è‚¡é¢†æ¶¨...",
            "source": "Financial Times",
            "author": "Bob Johnson",
            "published_at": datetime.now(pytz.UTC),
            "url": "https://example.com/article3"
        }
    ]
    
    categorized = classifier.categorize_articles(test_articles)
    
    print("åˆ†ç±»ç»“æœ:")
    for category, articles in categorized.items():
        print(f"  {classifier.categories.get(category, {}).get('emoji', 'ğŸ“„')} {category}: {len(articles)} ç¯‡")
        for article in articles:
            print(f"    - {article['title']} (ç½®ä¿¡åº¦: {article['confidence']:.2f})")
    
    print("âœ… åˆ†ç±»åŠŸèƒ½æµ‹è¯•å®Œæˆ\n")
    return categorized

def test_aggregation():
    """æµ‹è¯•å†…å®¹èšåˆåŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•å†…å®¹èšåˆåŠŸèƒ½...")
    
    aggregator = ContentAggregator()
    
    # æµ‹è¯•ç›¸ä¼¼æ–‡ç« 
    test_articles = [
        {
            "title": "OpenAIå‘å¸ƒæ–°ä¸€ä»£è¯­è¨€æ¨¡å‹",
            "summary": "OpenAIä»Šæ—¥å‘å¸ƒäº†å…¨æ–°çš„è¯­è¨€æ¨¡å‹ï¼Œæ€§èƒ½ç›¸æ¯”å‰ä»£æå‡æ˜¾è‘—...",
            "source": "TechCrunch",
            "author": "John Smith",
            "published_at": datetime.now(pytz.UTC),
            "url": "https://example.com/article1"
        },
        {
            "title": "OpenAIæ¨å‡ºæ–°çš„AIæ¨¡å‹",
            "summary": "æœ€æ–°ä¸€ä»£AIæ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚...",
            "source": "The Verge",
            "author": "Jane Doe",
            "published_at": datetime.now(pytz.UTC) - timedelta(minutes=30),
            "url": "https://example.com/article2"
        },
        {
            "title": "å¦‚ä½•é«˜æ•ˆå­¦ä¹ ç®—æ³•",
            "summary": "æœ¬æ–‡ä»‹ç»äº†å‡ ç§é«˜æ•ˆå­¦ä¹ ç®—æ³•çš„æ–¹æ³•å’Œå®è·µæŠ€å·§...",
            "source": "Hacker News",
            "author": "Bob Johnson",
            "published_at": datetime.now(pytz.UTC) - timedelta(hours=2),
            "url": "https://example.com/article3"
        }
    ]
    
    aggregated = aggregator.aggregate_articles(test_articles)
    
    print(f"åŸå§‹æ–‡ç« æ•°é‡: {len(test_articles)}")
    print(f"èšåˆåæ–‡ç« æ•°é‡: {len(aggregated)}")
    
    print("èšåˆç»“æœ:")
    for i, article in enumerate(aggregated):
        print(f"  {i+1}. {article['title']} (æ¥æº: {article['source']})")
        if 'related_articles' in article:
            print(f"     åŒ…å« {len(article['related_articles'])} ä¸ªç›¸å…³æ–‡ç« ")
    
    print("âœ… èšåˆåŠŸèƒ½æµ‹è¯•å®Œæˆ\n")
    return aggregated

def test_summary_generation():
    """æµ‹è¯•æ‘˜è¦ç”ŸæˆåŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•æ‘˜è¦ç”ŸæˆåŠŸèƒ½...")
    
    generator = SummaryGenerator()
    
    test_content = """
    OpenAIä»Šæ—¥å‘å¸ƒäº†å…¨æ–°çš„è¯­è¨€æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†çªç ´æ€§è¿›å±•ã€‚
    æ–°æ¨¡å‹ä¸ä»…åœ¨è¯­è¨€ç†è§£æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œåœ¨ä»£ç ç”Ÿæˆã€æ•°å­¦æ¨ç†ç­‰å¤šä¸ªé¢†åŸŸä¹Ÿæœ‰æ˜¾è‘—æå‡ã€‚
    ç ”ç©¶äººå‘˜è¡¨ç¤ºï¼Œè¿™ä¸€è¿›å±•å°†æ¨åŠ¨äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨æ›´å¤šå®é™…åœºæ™¯ä¸­çš„åº”ç”¨ã€‚
    è¯¥æ¨¡å‹é‡‡ç”¨äº†åˆ›æ–°çš„è®­ç»ƒæ–¹æ³•ï¼Œä½¿å¾—å…¶åœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶æ›´åŠ å¯é å’Œå®‰å…¨ã€‚
    æ­¤å¤–ï¼Œæ–°æ¨¡å‹è¿˜ç‰¹åˆ«æ³¨é‡ä¼¦ç†è€ƒé‡ï¼Œåœ¨æœ‰å®³å†…å®¹è¿‡æ»¤æ–¹é¢æœ‰äº†æ˜¾è‘—æ”¹è¿›ã€‚
    """
    
    summary = generator.generate_summary("OpenAIå‘å¸ƒæ–°ä¸€ä»£è¯­è¨€æ¨¡å‹", test_content)
    
    print(f"åŸæ–‡é•¿åº¦: {len(test_content)} å­—ç¬¦")
    print(f"æ‘˜è¦é•¿åº¦: {len(summary)} å­—ç¬¦")
    print(f"æ‘˜è¦å†…å®¹: {summary}")
    
    print("âœ… æ‘˜è¦ç”ŸæˆåŠŸèƒ½æµ‹è¯•å®Œæˆ\n")
    return summary

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ DeepSpace Matrix Daily - åŠŸèƒ½æµ‹è¯•")
    print("="*50)
    
    # æ‰§è¡Œå„é¡¹æµ‹è¯•
    categorized_result = test_classification()
    aggregated_result = test_aggregation()
    summary_result = test_summary_generation()
    
    print("="*50)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("- åˆ†ç±»åŠŸèƒ½æ­£å¸¸")
    print("- èšåˆåŠŸèƒ½æ­£å¸¸") 
    print("- æ‘˜è¦ç”ŸæˆåŠŸèƒ½æ­£å¸¸")
    print("\nâœ… DeepSpace Matrix Daily åˆ†ç±»èšåˆç³»ç»Ÿå‡†å¤‡å°±ç»ªï¼")

if __name__ == "__main__":
    main()