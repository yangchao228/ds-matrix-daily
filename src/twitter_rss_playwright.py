#!/usr/bin/env python3
"""
Playwright Twitter RSS Generator
ä½¿ç”¨æµè§ˆå™¨è‡ªåŠ¨åŒ–è·å– Twitter æ•°æ®å¹¶ç”Ÿæˆ RSS feed
ä¸ä¾èµ– Twitter APIï¼Œä¸ä¾èµ–ç¬¬ä¸‰æ–¹ RSS æº
"""
import json
import asyncio
from playwright.async_api import async_playwright
from datetime import datetime, timedelta
import pytz
import xml.etree.ElementTree as ET
from xml.dom import minidom
import hashlib
import sys
from pathlib import Path

# é…ç½®æ–‡ä»¶è·¯å¾„
CONFIG_PATH = Path("/root/.openclaw/workspace/twitter-daily-report-config.json")

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    try:
        with open(CONFIG_PATH, 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        print("âœ— é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°")
        return None
    except json.JSONDecodeError as e:
        print(f"âœ— é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
        return None

async def get_user_tweets(username, browser):
    """
    ä½¿ç”¨ Playwright è·å–ç”¨æˆ·çš„æ¨æ–‡
    """
    print(f"\nğŸ“¥ æ­£åœ¨è·å– @{username} çš„æ¨æ–‡...")

    # åˆ›å»ºæ–°çš„æµè§ˆå™¨ä¸Šä¸‹æ–‡ï¼ˆå¸¦ç”¨æˆ·ä»£ç†ï¼‰
    context = await browser.new_context(
        user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        viewport={'width': 1280, 'height': 800}
    )

    page = await context.new_page()

    try:
        # è®¿é—®ç”¨æˆ·ä¸»é¡µ
        url = f"https://x.com/{username}"
        print(f"  è®¿é—®: {url}")

        await page.goto(url, wait_until='networkidle', timeout=30000)

        # ç­‰å¾…é¡µé¢åŠ è½½
        await asyncio.sleep(3)

        # è·å–æ¨æ–‡æ•°æ®
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„ Twitter DOM ç»“æ„è°ƒæ•´é€‰æ‹©å™¨
        tweets = []

        # å°è¯•å¤šç§é€‰æ‹©å™¨
        selectors = [
            'article[role="article"]',
            '[data-testid="tweet"]',
            '.tweet',
            '[role="article"]'
        ]

        tweet_elements = []
        for selector in selectors:
            try:
                tweet_elements = await page.query_selector_all(selector)
                if tweet_elements:
                    print(f"  âœ“ ä½¿ç”¨é€‰æ‹©å™¨: {selector}")
                    break
            except:
                continue

        if not tweet_elements:
            print("  âš ï¸  æœªæ‰¾åˆ°æ¨æ–‡å…ƒç´ ï¼Œå¯èƒ½éœ€è¦ç™»å½•")
            # å°è¯•å…¶ä»–æ–¹æ³•...

        # è§£ææ¨æ–‡æ•°æ®
        for i, element in enumerate(tweet_elements[:20]):  # æœ€å¤šè·å–20æ¡
            try:
                # è·å–æ¨æ–‡æ–‡æœ¬
                text_element = await element.query_selector('[data-testid="tweetText"]')
                text = await text_element.inner_text() if text_element else ""

                # è·å–æ—¶é—´
                time_element = await element.query_selector('time')
                time_str = await time_element.get_attribute('datetime') if time_element else ""

                # è·å–é“¾æ¥
                link_element = await element.query_selector('a[href*="/status/"]')
                link = await link_element.get_attribute('href') if link_element else ""

                if text:
                    tweets.append({
                        'text': text,
                        'time': time_str,
                        'link': f"https://x.com{link}" if link and not link.startswith('http') else link,
                        'username': username
                    })

            except Exception as e:
                print(f"    âš ï¸  è§£ææ¨æ–‡ {i} æ—¶å‡ºé”™: {e}")
                continue

        print(f"  âœ“ æ‰¾åˆ° {len(tweets)} æ¡æ¨æ–‡")
        return tweets

    except Exception as e:
        print(f"  âœ— è·å–æ¨æ–‡å¤±è´¥: {e}")
        return []
    finally:
        await context.close()

def filter_tweets_by_date(tweets, days_back=1):
    """æŒ‰æ—¥æœŸè¿‡æ»¤æ¨æ–‡"""
    cutoff_time = datetime.now(pytz.UTC) - timedelta(days=days_back)
    filtered = []

    for tweet in tweets:
        try:
            if tweet['time']:
                tweet_time = datetime.fromisoformat(tweet['time'].replace('Z', '+00:00'))
                if tweet_time >= cutoff_time:
                    filtered.append(tweet)
        except:
            # å¦‚æœæ— æ³•è§£ææ—¶é—´ï¼Œä¿ç•™
            filtered.append(tweet)

    return filtered

def generate_rss_feed(tweets_by_user, config):
    """ç”Ÿæˆ RSS feed"""
    root = ET.Element('rss')
    root.set('version', '2.0')

    channel = ET.SubElement(root, 'channel')

    # æ·»åŠ  channel ä¿¡æ¯
    ET.SubElement(channel, 'title').text = 'Twitter Daily Report'
    ET.SubElement(channel, 'description').text = f'Twitter æ—¥æŠ¥ - {datetime.now().strftime("%Y-%m-%d")}'
    ET.SubElement(channel, 'link').text = 'https://x.com'
    ET.SubElement(channel, 'lastBuildDate').text = datetime.now().strftime('%a, %d %b %Y %H:%M:%S %z')

    # æ·»åŠ æ¨æ–‡æ¡ç›®
    for username, tweets in tweets_by_user.items():
        for i, tweet in enumerate(tweets):
            item = ET.SubElement(channel, 'item')

            # æ ‡é¢˜
            title_text = tweet['text'][:100] + '...' if len(tweet['text']) > 100 else tweet['text']
            ET.SubElement(item, 'title').text = f"@{username}: {title_text}"

            # æè¿°
            ET.SubElement(item, 'description').text = tweet['text']

            # é“¾æ¥
            if tweet['link']:
                ET.SubElement(item, 'link').text = tweet['link']

            # å‘å¸ƒæ—¥æœŸ
            if tweet['time']:
                try:
                    tweet_time = datetime.fromisoformat(tweet['time'].replace('Z', '+00:00'))
                    ET.SubElement(item, 'pubDate').text = tweet_time.strftime('%a, %d %b %Y %H:%M:%S %z')
                except:
                    pass

            # GUID
            guid = ET.SubElement(item, 'guid')
            guid.set('isPermaLink', 'false')
            guid.text = hashlib.md5(f"{username}_{tweet['text']}_{i}".encode()).hexdigest()

            # ä½œè€…
            ET.SubElement(item, 'author').text = f"@{username}"

    # ç¾åŒ– XML
    rough_string = ET.tostring(root, 'utf-8')
    reparsed = minidom.parseString(rough_string)
    return reparsed.toprettyxml(indent="  ")

async def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("Playwright Twitter RSS Generator")
    print("=" * 60)

    # åŠ è½½é…ç½®
    config = load_config()
    if not config:
        sys.exit(1)

    accounts = config.get('accounts', [])
    days_back = config.get('days_back', 1)

    print(f"\nç›‘æ§è´¦å·: {accounts}")
    print(f"æ—¶é—´èŒƒå›´: {days_back} å¤©")

    # å¯åŠ¨æµè§ˆå™¨
    async with async_playwright() as p:
        # å¯åŠ¨ Chromiumï¼ˆheadless æ¨¡å¼ï¼‰
        browser = await p.chromium.launch(headless=True)

        tweets_by_user = {}

        # è·å–æ¯ä¸ªè´¦å·çš„æ¨æ–‡
        for username in accounts:
            tweets = await get_user_tweets(username, browser)
            filtered_tweets = filter_tweets_by_date(tweets, days_back)
            tweets_by_user[username] = filtered_tweets

        await browser.close()

    # ç”Ÿæˆ RSS feed
    print("\nğŸ“Š ç”Ÿæˆ RSS feed...")
    rss_feed = generate_rss_feed(tweets_by_user, config)

    # ä¿å­˜ RSS feed
    data_dir = Path(config.get('dataDir', '/root/.openclaw/workspace/twitter-data'))
    data_dir.mkdir(parents=True, exist_ok=True)

    date_str = datetime.now().strftime("%Y-%m-%d")
    rss_path = data_dir / f"twitter-feed-{date_str}.xml"

    with open(rss_path, 'w', encoding='utf-8') as f:
        f.write(rss_feed)

    print(f"âœ“ RSS feed å·²ä¿å­˜: {rss_path}")

    # ç»Ÿè®¡ä¿¡æ¯
    total_tweets = sum(len(tweets) for tweets in tweets_by_user.values())
    print(f"\nç»Ÿè®¡: æ€»å…±è·å– {total_tweets} æ¡æ¨æ–‡")

    for username, tweets in tweets_by_user.items():
        print(f"  @{username}: {len(tweets)} æ¡")

    print("\n" + "=" * 60)
    print("âœ“ å®Œæˆï¼")
    print("=" * 60)

if __name__ == "__main__":
    asyncio.run(main())
